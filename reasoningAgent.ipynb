{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T00:49:21.685782Z",
     "start_time": "2025-12-07T00:49:21.680640Z"
    }
   },
   "source": [
    "# %% Minimal setup\n",
    "# If needed (uncomment in a notebook):\n",
    "# !pip install requests python-dotenv\n",
    "\n",
    "import os, json, textwrap, re, time\n",
    "from http.client import responses\n",
    "\n",
    "import requests\n",
    "from mpmath.math2 import math_sqrt\n",
    "\n",
    "API_KEY  = os.getenv(\"OPENAI_API_KEY\", \"cse476\")\n",
    "API_BASE = os.getenv(\"API_BASE\", \"http://10.4.58.53:41701/v1\")\n",
    "MODEL    = os.getenv(\"MODEL_NAME\", \"bens_model\")\n",
    "\n",
    "def call_model_chat_completions(prompt: str,\n",
    "                                system: str = \"You are a helpful assistant. Reply with only the final answer—no explanation.\",\n",
    "                                model: str = MODEL,\n",
    "                                temperature: float = 0.0,\n",
    "                                timeout: int = 60) -> dict:\n",
    "    \"\"\"\n",
    "    Calls an OpenAI-style /v1/chat/completions endpoint and returns:\n",
    "    { 'ok': bool, 'text': str or None, 'raw': dict or None, 'status': int, 'error': str or None, 'headers': dict }\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE}/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\":  \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 128,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(url, headers=headers, json=payload, timeout=timeout)\n",
    "        status = resp.status_code\n",
    "        hdrs   = dict(resp.headers)\n",
    "        if status == 200:\n",
    "            data = resp.json()\n",
    "            text = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return {\"ok\": True, \"text\": text, \"raw\": data, \"status\": status, \"error\": None, \"headers\": hdrs}\n",
    "        else:\n",
    "            # try best-effort to surface error text\n",
    "            err_text = None\n",
    "            try:\n",
    "                err_text = resp.json()\n",
    "            except Exception:\n",
    "                err_text = resp.text\n",
    "            return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": status, \"error\": str(err_text), \"headers\": hdrs}\n",
    "    except requests.RequestException as e:\n",
    "        return {\"ok\": False, \"text\": None, \"raw\": None, \"status\": -1, \"error\": str(e), \"headers\": {}}\n"
   ],
   "outputs": [],
   "execution_count": 290
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# self reflection :First inference method\n",
    "This was implemented in the agent loop"
   ],
   "id": "d37f7a339d330d78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Three of thought: Second inference method\n",
   "id": "7d091daa889ab338"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T00:49:21.699697Z",
     "start_time": "2025-12-07T00:49:21.694657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Node:\n",
    "    def __init__(self, thought, children = None):\n",
    "        self.thought = thought\n",
    "        self.children = children or []\n",
    "\n",
    "class Tot:\n",
    "    def __init__(self, prompt, model = None, iterations = 3, maxTokens = 128, treeOutput = None):\n",
    "        self.root = Node(prompt)\n",
    "        self.model = model or MODEL\n",
    "        self.iterations = iterations\n",
    "        self.current_thoughts = [self.root]\n",
    "        self.maxTokens = maxTokens\n",
    "        self.treeOutput = \"\"\n",
    "\n",
    "\n",
    "    def EThoughts(self, thoughtN):\n",
    "        newThoughtNodes = []\n",
    "\n",
    "        for nd in thoughtN:\n",
    "            prompt = f\"Given the current thought: '{nd.thought}', provide three concise thoughts that expand this idea further.\"\n",
    "            response = call_model_chat_completions(prompt)\n",
    "\n",
    "            if response:\n",
    "                child = Node(response[\"text\"])\n",
    "                nd.children.append(child)\n",
    "                newThoughtNodes.append(child)\n",
    "\n",
    "        return newThoughtNodes\n",
    "\n",
    "\n",
    "    def Run(self):\n",
    "        iteration = 0\n",
    "        while self.current_thoughts and iteration < self.iterations:\n",
    "            #print(f\"Iteration {iteration + 1}:\")\n",
    "            self.current_thoughts = self.EThoughts(self.current_thoughts)\n",
    "\n",
    "            # for tNode in self.current_thoughts:\n",
    "            #     print(f\"Explored Thought: {tNode.thought}\")\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "\n",
    "    def updateThought(self, nThought):\n",
    "        self.root = Node(nThought)\n",
    "        self.current_thoughts = [self.root]\n",
    "\n",
    "\n",
    "    def showTree(self, Node, lv=0, prefix=\"\",buffer = None):\n",
    "\n",
    "        # Reset buffer only on first/top-level call\n",
    "        if lv == 0:\n",
    "            self.treeOutput = \"\"\n",
    "\n",
    "        connector = \"└── \" if lv > 0 else \"\"\n",
    "        #print(f\"{prefix}{connector}{Node.thought}\")\n",
    "        line = f\"{prefix}{connector}{Node.thought}\"\n",
    "\n",
    "        self.treeOutput += line + \"\\n\"\n",
    "\n",
    "        # Prepare indentation for children\n",
    "        child_prefix = prefix + (\"    \" if lv > 0 else \"\")\n",
    "\n",
    "        for child in Node.children:\n",
    "            self.showTree(child, lv + 1, child_prefix)\n",
    "\n",
    "    def selectAnswer(self, original_prompt: str):\n",
    "\n",
    "        self.showTree(self.root)\n",
    "\n",
    "        ## USE FOR TESTING\n",
    "        #print(\"Printing the ogPrompt\",original_prompt)\n",
    "        answer = call_model_chat_completions(original_prompt ,system= f\"You are given a list of thoughts to help you decide on the answer look at the prompt and select branch with the most nodes. respond with just the answer. Attached below is the train of thought {self.treeOutput}\")\n",
    "\n",
    "        #print(\"the final answer is\", answer[\"text\"])\n",
    "        #print(\"The tree out is\", self.treeOutput)\n",
    "\n",
    "        return answer[\"text\"]\n",
    "\n"
   ],
   "id": "f5c81dd678f4e031",
   "outputs": [],
   "execution_count": 291
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Self-consistency : Third inference method\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "2cb1f4f19c41211f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T00:49:21.706011Z",
     "start_time": "2025-12-07T00:49:21.702586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "def determineProblem(prompt):\n",
    "    problemType = call_model_chat_completions(prompt, system= \"Determine what type of problem this is and return one of the following choices \"\n",
    "                                                              \"[Math reasoning, common sense, logic]\")\n",
    "    return problemType[\"text\"]\n",
    "\n",
    "def selfConsistency(prompt, num_responses = 5):\n",
    "    responses = []\n",
    "    for _ in range(num_responses):\n",
    "\n",
    "        ## funny way to rem temperature: When ur girlfriend is hot\"mad\" she is going to say a lot more and complain. When she is cold she will be relaxed and say less amen\n",
    "        #Before solving Response{_} must be written down\n",
    "        response = call_model_chat_completions(prompt, system = f\"\", temperature= .8)\n",
    "        responses.append(response[\"text\"])\n",
    "\n",
    "    formatFinalAnswers = responses\n",
    "    #formatFinalAnswers  = \"\\n---\\n\".join([f\"{key}:\\n{value}\" for key, value in responses])\n",
    "\n",
    "    #print(\"The formatFinal answers\",formatFinalAnswers)\n",
    "    selectionPrompt = f\"\"\"\n",
    "\n",
    "    I have generated several responses for the given problem. Please evaluate them and determine which is the most accurate, comprehensive, and well written\"\n",
    "\n",
    "    Here are the responses:\n",
    "    {formatFinalAnswers}\n",
    "\n",
    "    Review all candidate responses, determine which one is the strongest.\n",
    "    Return the answer after the Response: Example 'Response0: Yes'\n",
    "    Return would be \"yes\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    goldenSolution = call_model_chat_completions(selectionPrompt)\n",
    "    #print(\"The golden solution: \", goldenSolution) USE FOR TESTING\n",
    "\n",
    "    return goldenSolution[\"text\"], formatFinalAnswers\n",
    "\n",
    "\n",
    "    ## ORIGINAL IMPLEMENTATION  ```````````\n",
    "    # finalAnswers = []\n",
    "    # for res in responses:\n",
    "    #     match = re.search(r\"\\*\\*Answer: (\\d+)\", res)\n",
    "    #     if match:\n",
    "    #         finalAnswers.append(int(match.group(1)))\n",
    "    #\n",
    "    # print(f\"All extracted answers: {finalAnswers}\")\n",
    "    #\n",
    "    # # majority vote\n",
    "    # if finalAnswers:\n",
    "    #     VoteResult = Counter(finalAnswers).most_common(1)[0]\n",
    "    #     print(f\"Most consistent answer: {VoteResult[0]} (appeared {VoteResult[1]} times)\")\n",
    "    #     return VoteResult\n",
    "    #\n",
    "    # return None\n",
    "\n",
    "    ##return responses\n",
    "\n",
    "\n",
    "def runSelfConsistency(prompt):\n",
    "    #problemType = determineProblem(prompt)\n",
    "    #print(problemType)\n",
    "    Answers = selfConsistency(prompt, num_responses= 5)\n",
    "    return Answers[0]\n",
    "    print(\"The golden solution is\", Answers[0], \"\\n\")\n",
    "    # for i in Answers[1]:\n",
    "    #     print(i)\n",
    "\n",
    "\n",
    "# prompt = \"For certain physical scenarios, it is impossible to model forces as being due to gradient of potentials. This is often due to macrophysical considerations that yield forces as arising from a macroscopic statistical average of microstates. For example, friction is caused by the gradients of numerous electrostatic potentials between the atoms, but manifests as a force model that is independent of any macroscale position vector. Nonconservative forces other than friction include other contact forces, tension, compression, and drag. However, for any sufficiently detailed description, all these forces are the results of conservative ones since each of these macroscopic forces are the net results of the gradients of microscopic potentials. It is always possible to model forces as being due to what?\"\n",
    "# runSelfConsistency(prompt)\n",
    "\n",
    "#\n",
    "# prompt = \"if there are three cars in the parking lot and 289 more cars arrive, how many cars are in the parking lot\"\n",
    "# problemType = determineProblem(prompt)\n",
    "# print(problemType)\n",
    "#\n",
    "# Answers = selfConsistency(prompt, num_responses= 5)\n",
    "# #print(Answers[0])\n",
    "#\n",
    "#\n",
    "# print(\"The golden solution is\", Answers[0])\n",
    "# for i in Answers[1]:\n",
    "#     print(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9e9dfc7f8604a0a2",
   "outputs": [],
   "execution_count": 292
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Agent loop\n",
    "\n",
    "Action route:\n",
    "1. Math or logic problems: self-consistency\n",
    "2. complex problems strategic planning, exploration, and backtracking: tree of thought\n",
    "3. Common sense"
   ],
   "id": "c701bebbb168dce0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T00:49:21.714245Z",
     "start_time": "2025-12-07T00:49:21.708441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class agent:\n",
    "    #actionList =  [\"tot\", \"Consistency\", \"reflection\" ]\n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "\n",
    "        self.action_list = [\"tot\", \"Consistency\", \"reflection\" ]\n",
    "        self.problem_types = [\"Math reasoning\", \"Common sense\", \"logic\"]\n",
    "\n",
    "    # def reason(self, context):\n",
    "    #     #print(\"working\")\n",
    "\n",
    "    def reflection(self, prompt: str):\n",
    "        #print(\"yes\")\n",
    "\n",
    "        # tot_agent = Tot(prompt)\n",
    "        # tot_agent.Run()\n",
    "        # tot_agent.showTree(tot_agent.root)\n",
    "        # tot_agent.selectAnswer(prompt)\n",
    "\n",
    "        oringialAnswer = runSelfConsistency(prompt)\n",
    "\n",
    "        reflectionPrompt = f\"\"\"\n",
    "        You are a critic and solver.\n",
    "\n",
    "        here is the original question:\n",
    "        {prompt}\n",
    "\n",
    "        here is an initial attempt at the solution\n",
    "        {oringialAnswer}\n",
    "\n",
    "        2. Provide only the final answer after correction.\n",
    "        \"\"\"\n",
    "\n",
    "        system_reflect = (\n",
    "        \"You are a strict but helpful reviewer. \"\n",
    "        \"Make sure the output is only the FINAL ANSWER.\"\n",
    "        )\n",
    "\n",
    "        refined = call_model_chat_completions(\n",
    "            reflectionPrompt,\n",
    "            system=system_reflect\n",
    "        )\n",
    "\n",
    "        if not refined or \"text\" not in refined:\n",
    "            return oringialAnswer\n",
    "\n",
    "\n",
    "        return refined[\"text\"]\n",
    "\n",
    "\n",
    "\n",
    "    def planAction(self, prompt: str):\n",
    "\n",
    "        ##example\n",
    "        tests = [\n",
    "            {\n",
    "                \"id\": \"math_inequality\",\n",
    "                \"type\": \"numeric\",  # grader will prefer numeric extraction\n",
    "                \"prompt\": \"Solve for the smallest integer n such that 3n + 5 > 26. Answer with just the integer.\",\n",
    "                \"expected\": \"8\",    # Because 3n > 21 => n > 7, smallest integer is 8\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"commonsense_ice\",\n",
    "                \"type\": \"text\",\n",
    "                \"prompt\": (\n",
    "                    \"You place an ice cube in a glass of water and mark the water level. \"\n",
    "                    \"After the ice melts, does the water level rise, fall, or stay the same? \"\n",
    "                    \"Answer with exactly one of: 'rise', 'fall', 'stay the same'.\"\n",
    "                ),\n",
    "                \"expected\": \"stay the same\",\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"logic_race\",\n",
    "                \"type\": \"text\",\n",
    "                \"prompt\": (\n",
    "                    \"In a race, you pass the person in second place. What position are you now in? \"\n",
    "                    \"Answer with a single word like 'first', 'second', 'third'.\"\n",
    "                ),\n",
    "                \"expected\": \"second\",\n",
    "            },\n",
    "            ]\n",
    "        systemPrompt = f\"\"\"\n",
    "        Determine what type of problem this is and return one of the following choices \"[Math reasoning, Common sense, logic]\"\n",
    "        attached below are examples of each problem type. When returning the answer just return the text\n",
    "        {tests}\n",
    "        \"\"\"\n",
    "        #action =  [\"tot\", \"Consistency\", \"reflection\" ]\n",
    "        #ProblemTypes = [\"Math reasoning\", \"Common sense\", \"logic\"]\n",
    "\n",
    "        DefineProblem = call_model_chat_completions(prompt, system= systemPrompt)\n",
    "        #DefineProblem = call_model_chat_completions(prompt, system=systemPrompt)\n",
    "\n",
    "        raw_text = (DefineProblem or {}).get(\"text\")\n",
    "\n",
    "        if not raw_text:\n",
    "            return self.action_list[1]\n",
    "\n",
    "        label = raw_text.strip()\n",
    "        if not label:\n",
    "            return self.action_list[1]\n",
    "\n",
    "\n",
    "        if not DefineProblem or \"text\" not in DefineProblem:\n",
    "            #print(\"Could not classify problem, defaulting to Consistency.\")\n",
    "            return self.action_list[1]  # default to self-consistency\n",
    "            #return action[1]\n",
    "\n",
    "        label = DefineProblem[\"text\"].strip()\n",
    "\n",
    "        ## Math Tree of Thought\n",
    "        if label == self.problem_types[0]:\n",
    "            #print(\"it is\" ,DefineProblem[\"text\"])\n",
    "            return self.action_list[0]\n",
    "\n",
    "         ## common sense Self-Consistency\n",
    "        elif label == self.problem_types[1]:\n",
    "            return self.action_list[1]\n",
    "\n",
    "        ## logic puzzles\n",
    "        elif label == self.problem_types[2]:\n",
    "           # print(\"it is\" ,DefineProblem[\"text\"])\n",
    "            return self.action_list[2]\n",
    "\n",
    "        return self.action_list[1]\n",
    "\n",
    "\n",
    "    def executeAction(self, action: str, prompt: str):\n",
    "        actionList =  [\"tot\", \"Consistency\", \"reflection\" ]\n",
    "        if action == actionList[0]:\n",
    "            #print(\"\\nPreforming Train of thought\")\n",
    "            tot_agent = Tot(prompt)\n",
    "            tot_agent.Run()\n",
    "            tot_agent.showTree(tot_agent.root)\n",
    "            return tot_agent.selectAnswer(prompt)\n",
    "\n",
    "        elif action == actionList[1]:\n",
    "            #print(\"\\npreforming consistency\")\n",
    "            return runSelfConsistency(prompt)\n",
    "\n",
    "        elif action == actionList[2]:\n",
    "            #print(\"\\npreforming reflection\")\n",
    "            return self.reflection(prompt)\n",
    "            #return runSelfConsistency(prompt)\n",
    "\n",
    "\n",
    "        else:\n",
    "            #print(\"Unknown action:\", action)\n",
    "            return None\n",
    "\n",
    "    def runAgent(self, task):\n",
    "        # Extract prompt from task\n",
    "        if isinstance(task, dict):\n",
    "            prompt = task.get(\"input\") or task.get(\"prompt\")\n",
    "        else:\n",
    "            prompt = str(task)\n",
    "\n",
    "        if not prompt:\n",
    "            raise ValueError(\"runAgent: No prompt found in task.\")\n",
    "\n",
    "        # reasoning context\n",
    "        # self.reason({\"task\": task})\n",
    "\n",
    "        # Decide which technique to use\n",
    "        action = self.planAction(prompt)\n",
    "        #print(\"Chosen action:\", action)\n",
    "\n",
    "        if action is None:\n",
    "            action = self.action_list[1]  # \"Consistency\"\n",
    "\n",
    "        # Execute the technique\n",
    "        answer = self.executeAction(action, prompt)\n",
    "\n",
    "        if not isinstance(answer, str) or not answer.strip():\n",
    "            answer = \"NO_ANSWER_GENERATED_DUE_TO_API_OR_CONNECTION_ERROR\"\n",
    "\n",
    "        #\n",
    "        # if answer is None:\n",
    "        #     answer = \"\"\n",
    "        # elif not isinstance(answer, str):\n",
    "        #     answer = str(answer)\n",
    "\n",
    "        # if len(answer) > 4999:\n",
    "        #     answer = answer[:4999]\n",
    "        #Shorten this answer to the minimum number of words needed {answer}\n",
    "\n",
    "        answer = call_model_chat_completions(f\"The answer is {answer}\", system= \"Return ONLY the essential answer no explanation needed\")\n",
    "        #print(answer[\"text\"]) TESTING\n",
    "        return answer[\"text\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#      agent = agent()\n",
    "#\n",
    "#      task = {\n",
    "#          \"input\": \"Is it possible to get killed walking to the Very Large Telescope? Facts: The Very Large Telescope is in the Atacama Desert The Atacama Desert is the driest hot desert in the world.\"\n",
    "#     }\n",
    "#\n",
    "#      result = agent.runAgent(task)\n",
    "#      print(\"Final answer:\", result)\n",
    "\n",
    "\n",
    "\n",
    "# A1 = agent\n",
    "# Action = A1.planAction(\"You place an ice cube in a glass of water and mark the water level. \"\n",
    "#             \"After the ice melts, does the water level rise, fall, or stay the same? \"\n",
    "#             \"Answer with exactly one of: 'rise', 'fall', 'stay the same'.\")\n",
    "# A1.executeAction(Action)\n",
    "\n"
   ],
   "id": "c5e089ff862d2591",
   "outputs": [],
   "execution_count": 293
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final testing: Answer generation",
   "id": "844a7dafad89a1e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T00:49:23.963998Z",
     "start_time": "2025-12-07T00:49:21.717472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Generate a placeholder answer file that matches the expected auto-grader format.\n",
    "\n",
    "Replace the placeholder logic inside `build_answers()` with your own agent loop\n",
    "before submitting so the ``output`` fields contain your real predictions.\n",
    "\n",
    "Reads the input questions from cse_476_final_project_test_data.json and writes\n",
    "an answers JSON file where each entry contains a string under the \"output\" key.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "\n",
    "INPUT_PATH = Path(\"first50.json\")\n",
    "OUTPUT_PATH = Path(\"cse_476_final_project_answers.json\")\n",
    "\n",
    "# INPUT_PATH = Path(\"question.json\")\n",
    "# OUTPUT_PATH = Path(\"answers.json\")\n",
    "\n",
    "def load_questions(path: Path) -> List[Dict[str, Any]]:\n",
    "    with path.open(\"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Input file must contain a list of question objects.\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def build_answers(questions: List[Dict[str, Any]]) -> List[Dict[str, str]]:\n",
    "    answers = []\n",
    "    count = 0\n",
    "    my_agent = agent()   # create a single agent instance\n",
    "    for idx, question in enumerate(questions, start=1):\n",
    "        # Example: assume you have an agent loop that produces an answer string.\n",
    "        # result = call_model_chat_completions(question[\"input\"])\n",
    "        # answers.append({\"output\": result[\"text\"]})\n",
    "        result = my_agent.runAgent(question)\n",
    "        answers.append({\"output\": result})\n",
    "\n",
    "        count += 1\n",
    "        if count == 100:\n",
    "            count = 0\n",
    "            print(idx, \"\\n\")\n",
    "\n",
    "        # real_answer = agent_loop(question[\"input\"])\n",
    "        # answers.append({\"output\": real_answer})\n",
    "\n",
    "        # placeholder_answer = f\"Placeholder answer for question {idx}\"\n",
    "        # answers.append({\"output\": placeholder_answer})\n",
    "    return answers\n",
    "\n",
    "\n",
    "def validate_results(\n",
    "    questions: List[Dict[str, Any]], answers: List[Dict[str, Any]]\n",
    ") -> None:\n",
    "    if len(questions) != len(answers):\n",
    "        raise ValueError(\n",
    "            f\"Mismatched lengths: {len(questions)} questions vs {len(answers)} answers.\"\n",
    "        )\n",
    "    for idx, answer in enumerate(answers):\n",
    "        if \"output\" not in answer:\n",
    "            raise ValueError(f\"Missing 'output' field for answer index {idx}.\")\n",
    "        if not isinstance(answer[\"output\"], str):\n",
    "            raise TypeError(\n",
    "                f\"Answer at index {idx} has non-string output: {type(answer['output'])}\"\n",
    "            )\n",
    "        if len(answer[\"output\"]) >= 5000:\n",
    "            raise ValueError(\n",
    "                f\"Answer at index {idx} exceeds 5000 characters \"\n",
    "                f\"({len(answer['output'])} chars). Please make sure your answer does not include any intermediate results.\"\n",
    "            )\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    questions = load_questions(INPUT_PATH)\n",
    "    answers = build_answers(questions)\n",
    "\n",
    "    with OUTPUT_PATH.open(\"w\") as fp:\n",
    "        json.dump(answers, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with OUTPUT_PATH.open(\"r\") as fp:\n",
    "        saved_answers = json.load(fp)\n",
    "    validate_results(questions, saved_answers)\n",
    "    print(\n",
    "        f\"Wrote {len(answers)} answers to {OUTPUT_PATH} \"\n",
    "        \"and validated format successfully.\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ],
   "id": "ac12cd35cf91a41a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[294]\u001B[39m\u001B[32m, line 95\u001B[39m\n\u001B[32m     88\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m     89\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mWrote \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(answers)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m answers to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mOUTPUT_PATH\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     90\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mand validated format successfully.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     91\u001B[39m     )\n\u001B[32m     94\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[294]\u001B[39m\u001B[32m, line 80\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     78\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmain\u001B[39m() -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     79\u001B[39m     questions = load_questions(INPUT_PATH)\n\u001B[32m---> \u001B[39m\u001B[32m80\u001B[39m     answers = \u001B[43mbuild_answers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     82\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m OUTPUT_PATH.open(\u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[32m     83\u001B[39m         json.dump(answers, fp, ensure_ascii=\u001B[38;5;28;01mFalse\u001B[39;00m, indent=\u001B[32m2\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[294]\u001B[39m\u001B[32m, line 41\u001B[39m, in \u001B[36mbuild_answers\u001B[39m\u001B[34m(questions)\u001B[39m\n\u001B[32m     36\u001B[39m my_agent = agent()   \u001B[38;5;66;03m# create a single agent instance\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, question \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(questions, start=\u001B[32m1\u001B[39m):\n\u001B[32m     38\u001B[39m     \u001B[38;5;66;03m# Example: assume you have an agent loop that produces an answer string.\u001B[39;00m\n\u001B[32m     39\u001B[39m     \u001B[38;5;66;03m# result = call_model_chat_completions(question[\"input\"])\u001B[39;00m\n\u001B[32m     40\u001B[39m     \u001B[38;5;66;03m# answers.append({\"output\": result[\"text\"]})\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     result = \u001B[43mmy_agent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrunAgent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     42\u001B[39m     answers.append({\u001B[33m\"\u001B[39m\u001B[33moutput\u001B[39m\u001B[33m\"\u001B[39m: result})\n\u001B[32m     44\u001B[39m     count += \u001B[32m1\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[293]\u001B[39m\u001B[32m, line 171\u001B[39m, in \u001B[36magent.runAgent\u001B[39m\u001B[34m(self, task)\u001B[39m\n\u001B[32m    168\u001B[39m     action = \u001B[38;5;28mself\u001B[39m.action_list[\u001B[32m1\u001B[39m]  \u001B[38;5;66;03m# \"Consistency\"\u001B[39;00m\n\u001B[32m    170\u001B[39m \u001B[38;5;66;03m# Execute the technique\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m answer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexecuteAction\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(answer, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m answer.strip():\n\u001B[32m    174\u001B[39m     answer = \u001B[33m\"\u001B[39m\u001B[33mNO_ANSWER_GENERATED_DUE_TO_API_OR_CONNECTION_ERROR\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[293]\u001B[39m\u001B[32m, line 138\u001B[39m, in \u001B[36magent.executeAction\u001B[39m\u001B[34m(self, action, prompt)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m tot_agent.selectAnswer(prompt)\n\u001B[32m    136\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m action == actionList[\u001B[32m1\u001B[39m]:\n\u001B[32m    137\u001B[39m     \u001B[38;5;66;03m#print(\"\\npreforming consistency\")\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m138\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrunSelfConsistency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m action == actionList[\u001B[32m2\u001B[39m]:\n\u001B[32m    141\u001B[39m     \u001B[38;5;66;03m#print(\"\\npreforming reflection\")\u001B[39;00m\n\u001B[32m    142\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reflection(prompt)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[292]\u001B[39m\u001B[32m, line 63\u001B[39m, in \u001B[36mrunSelfConsistency\u001B[39m\u001B[34m(prompt)\u001B[39m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrunSelfConsistency\u001B[39m(prompt):\n\u001B[32m     61\u001B[39m     \u001B[38;5;66;03m#problemType = determineProblem(prompt)\u001B[39;00m\n\u001B[32m     62\u001B[39m     \u001B[38;5;66;03m#print(problemType)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m     Answers = \u001B[43mselfConsistency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_responses\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Answers[\u001B[32m0\u001B[39m]\n\u001B[32m     65\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mThe golden solution is\u001B[39m\u001B[33m\"\u001B[39m, Answers[\u001B[32m0\u001B[39m], \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[292]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mselfConsistency\u001B[39m\u001B[34m(prompt, num_responses)\u001B[39m\n\u001B[32m      9\u001B[39m responses = []\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_responses):\n\u001B[32m     11\u001B[39m \n\u001B[32m     12\u001B[39m     \u001B[38;5;66;03m## funny way to rem temperature: When ur girlfriend is hot\"mad\" she is going to say a lot more and complain. When she is cold she will be relaxed and say less amen\u001B[39;00m\n\u001B[32m     13\u001B[39m     \u001B[38;5;66;03m#Before solving Response{_} must be written down\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     response = \u001B[43mcall_model_chat_completions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msystem\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m.8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m     responses.append(response[\u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     17\u001B[39m formatFinalAnswers = responses\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[290]\u001B[39m\u001B[32m, line 40\u001B[39m, in \u001B[36mcall_model_chat_completions\u001B[39m\u001B[34m(prompt, system, model, temperature, timeout)\u001B[39m\n\u001B[32m     29\u001B[39m payload = {\n\u001B[32m     30\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m     31\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [\n\u001B[32m   (...)\u001B[39m\u001B[32m     36\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmax_tokens\u001B[39m\u001B[33m\"\u001B[39m: \u001B[32m128\u001B[39m,\n\u001B[32m     37\u001B[39m }\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m     resp = \u001B[43mrequests\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     41\u001B[39m     status = resp.status_code\n\u001B[32m     42\u001B[39m     hdrs   = \u001B[38;5;28mdict\u001B[39m(resp.headers)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/api.py:115\u001B[39m, in \u001B[36mpost\u001B[39m\u001B[34m(url, data, json, **kwargs)\u001B[39m\n\u001B[32m    103\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(url, data=\u001B[38;5;28;01mNone\u001B[39;00m, json=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m    104\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[32m    105\u001B[39m \n\u001B[32m    106\u001B[39m \u001B[33;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    112\u001B[39m \u001B[33;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[32m    113\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpost\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/api.py:59\u001B[39m, in \u001B[36mrequest\u001B[39m\u001B[34m(method, url, **kwargs)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m sessions.Session() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/sessions.py:589\u001B[39m, in \u001B[36mSession.request\u001B[39m\u001B[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[39m\n\u001B[32m    584\u001B[39m send_kwargs = {\n\u001B[32m    585\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtimeout\u001B[39m\u001B[33m\"\u001B[39m: timeout,\n\u001B[32m    586\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mallow_redirects\u001B[39m\u001B[33m\"\u001B[39m: allow_redirects,\n\u001B[32m    587\u001B[39m }\n\u001B[32m    588\u001B[39m send_kwargs.update(settings)\n\u001B[32m--> \u001B[39m\u001B[32m589\u001B[39m resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/sessions.py:703\u001B[39m, in \u001B[36mSession.send\u001B[39m\u001B[34m(self, request, **kwargs)\u001B[39m\n\u001B[32m    700\u001B[39m start = preferred_clock()\n\u001B[32m    702\u001B[39m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m703\u001B[39m r = \u001B[43madapter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    705\u001B[39m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[32m    706\u001B[39m elapsed = preferred_clock() - start\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/adapters.py:644\u001B[39m, in \u001B[36mHTTPAdapter.send\u001B[39m\u001B[34m(self, request, stream, timeout, verify, cert, proxies)\u001B[39m\n\u001B[32m    641\u001B[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001B[32m    643\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m644\u001B[39m     resp = \u001B[43mconn\u001B[49m\u001B[43m.\u001B[49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    645\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    646\u001B[39m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    647\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    648\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m.\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    651\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    652\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    653\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    654\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    655\u001B[39m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    656\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    658\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[32m    659\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request=request)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001B[39m, in \u001B[36mHTTPConnectionPool.urlopen\u001B[39m\u001B[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[39m\n\u001B[32m    784\u001B[39m response_conn = conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    786\u001B[39m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m787\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    788\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    789\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    790\u001B[39m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    791\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    792\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    793\u001B[39m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m=\u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    794\u001B[39m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    795\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    796\u001B[39m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    797\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    799\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    800\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[32m    803\u001B[39m clean_exit = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001B[39m, in \u001B[36mHTTPConnectionPool._make_request\u001B[39m\u001B[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[39m\n\u001B[32m    532\u001B[39m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m534\u001B[39m     response = \u001B[43mconn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    535\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    536\u001B[39m     \u001B[38;5;28mself\u001B[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/urllib3/connection.py:565\u001B[39m, in \u001B[36mHTTPConnection.getresponse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    562\u001B[39m _shutdown = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.sock, \u001B[33m\"\u001B[39m\u001B[33mshutdown\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    564\u001B[39m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m565\u001B[39m httplib_response = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    567\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    568\u001B[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001B[39m, in \u001B[36mHTTPConnection.getresponse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1428\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1429\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1430\u001B[39m         \u001B[43mresponse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1431\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[32m   1432\u001B[39m         \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001B[39m, in \u001B[36mHTTPResponse.begin\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    329\u001B[39m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[32m    330\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m331\u001B[39m     version, status, reason = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    332\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m status != CONTINUE:\n\u001B[32m    333\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001B[39m, in \u001B[36mHTTPResponse._read_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m292\u001B[39m     line = \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[33m\"\u001B[39m\u001B[33miso-8859-1\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    293\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) > _MAXLINE:\n\u001B[32m    294\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[33m\"\u001B[39m\u001B[33mstatus line\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001B[39m, in \u001B[36mSocketIO.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m    717\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mcannot read from timed out object\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    718\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m719\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    720\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[32m    721\u001B[39m     \u001B[38;5;28mself\u001B[39m._timeout_occurred = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 294
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c18f30e242ee41da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "13bb40467ad28a3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
